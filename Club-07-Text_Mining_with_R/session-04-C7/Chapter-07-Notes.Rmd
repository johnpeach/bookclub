---
title: "Chapter 07 exercise"
author: "John Peach"
date: "4/12/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(lubridate)
library(ggplot2)
library(dplyr)
library(readr)
library(tidytext)
library(tidyr)
library(scales)
library(purrr)
library(broom)
```

```{r, message=FALSE}
tweets_julia <- read_csv("tweets_julia.csv")
tweets_dave <- read_csv("tweets_dave.csv")
tweets <- bind_rows(tweets_julia %>% 
                      mutate(person = "Julia"),
                    tweets_dave %>% 
                      mutate(person = "David")) %>% 
  mutate(timestamp = ymd_hms(timestamp))
```

```{r}
ggplot(tweets, aes(x = timestamp, fill = person)) +
  geom_histogram(position = 'identity', bins = 20, show.legend = FALSE) +
  facet_wrap(~person, ncol = 1)
```


```{r}
replace_reg1 <- "https://t.co/[A-Za-z\\d]+|"
replace_reg2 <- "http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https"
replace_reg <- paste0(replace_reg1, replace_reg2)
unnest_reg <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"
tidy_tweets <- tweets %>% 
  dplyr::filter(!str_detect(text, "^RT")) %>% 
  mutate(text = str_replace_all(text, replace_reg, "")) %>% 
  unnest_tokens(word, text, token = "regex", pattern = unnest_reg) %>% 
  dplyr::filter(!word %in% stop_words$word,
                str_detect(word, "[a-z]"))
```

```{r, message=FALSE}
frequency <- tidy_tweets %>% 
  group_by(person) %>% 
  count(word, sort = TRUE) %>% 
  left_join(tidy_tweets %>% 
              group_by(person) %>% 
              summarise(total = n())) %>% 
  mutate(freq = n / total)
frequency
```

```{r}
frequency <- frequency %>% 
  select(person, word, freq) %>% 
  spread(person, freq) %>% 
  arrange(Julia, David)
frequency
```

```{r}
ggplot(frequency, aes(Julia, David)) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  geom_abline(color = 'red')
```

```{r}
tidy_tweets <- tidy_tweets %>% 
  dplyr::filter(timestamp >= as.Date("2016-01-01"),
                timestamp < as.Date("2017-01-01"))
```

```{r}
word_ratio <- tidy_tweets %>% 
  dplyr::filter(!str_detect(word, "^@")) %>% 
  count(word, person) %>% 
  dplyr::filter(sum(n) >= 10) %>% 
  ungroup() %>% 
  spread(person, n, fill = 0) %>% 
  mutate_if(is.numeric, funs((. + 1) / sum(. + 1))) %>% 
  mutate(logratio = log(David / Julia)) %>% 
  arrange(desc(logratio))
```

```{r}
word_ratio %>% 
  arrange(abs(logratio))
```
```{r}
word_ratio %>% 
  group_by(logratio < 0) %>% 
  top_n(15, abs(logratio)) %>% 
  ungroup() %>% 
  mutate(word = reorder(word, logratio)) %>% 
  ggplot(aes(word, logratio, fill = logratio < 0)) +
    geom_col(show.legend = FALSE) +
    coord_flip() +
    ylab("log odds ratio (David/Julia)") +
    scale_fill_discrete(name = "", labels = c("David", "Julia"))
```

```{r}
words_by_time <- tidy_tweets %>% 
  dplyr::filter(!str_detect(word, "^@")) %>% 
  mutate(time_floor = floor_date(timestamp, unit = '1 month')) %>% 
  count(time_floor, person, word) %>% 
  ungroup() %>% 
  group_by(person, time_floor) %>% 
  mutate(time_total = sum(n)) %>% 
  group_by(word) %>% 
  mutate(word_total = sum(n)) %>% 
  ungroup() %>% 
  rename(count = n) %>% 
  dplyr::filter(word_total > 30)
words_by_time
```
```{r, message=FALSE, warning=FALSE}
nested_data <- words_by_time %>% 
  nest(-word, -person)

nested_data
```

```{r}
nested_models <- nested_data %>% 
  mutate(models = map(data, ~glm(cbind(count, time_total) ~ time_floor, .,
                                 family = "binomial")))
nested_models
```


```{r}
nested_models$temp <- map(nested_models$models, tidy)
nested_models %>% 
  unnest(temp) %>% 
  dplyr::filter(term == "time_floor") %>% 
  mutate(adjusted.p.value = p.adjust(p.value)) -> slopes

```


```{r}
top_slopes <- slopes %>% 
  dplyr::filter(adjusted.p.value < 0.1) %>% 
  select(-statistic, -p.value)
top_slopes
```
```{r}
words_by_time %>% 
  inner_join(top_slopes, by = c("word", "person")) %>% 
  dplyr::filter(person == "David") %>% 
  ggplot(aes(time_floor, count / time_total, colour = word, lty = word)) +
    geom_line(size = 1.3) +
    labs(x = NULL, y = "Word frequency")
```
```{r}
words_by_time %>% 
  inner_join(top_slopes, by = c("word", "person")) %>% 
  dplyr::filter(person == "Julia") %>% 
  ggplot(aes(time_floor, count / time_total, color = word, lty = word)) +
    geom_line(size = 1.3) +
    labs(x = NULL, y = "Word frequency")
```

```{r, message=FALSE}
tweets_julia <- read_csv("juliasilge_tweets.csv")
tweets_dave <- read_csv("drob_tweets.csv")
tweets <- bind_rows(tweets_julia %>% 
                      mutate(person = "Julia"),
                    tweets_dave %>% 
                      mutate(person = "David")) %>% 
  mutate(created_at = ymd_hms(created_at))
```

```{r, message=FALSE}
tweets %>% 
  select(-source) %>% 
  dplyr::filter(!str_detect(text, "^(RT|@)")) %>% 
  mutate(text = str_replace_all(text, replace_reg, "")) %>% 
  unnest_tokens(word, text, token = "regex", pattern = unnest_reg) %>% 
  anti_join(stop_words)

```
```{r, message=FALSE, warning=FALSE}
# This is broken as the new dataset is missing some columns. I fixed it so that
# it would run but it's output is garbage.
totals <- tidy_tweets %>% 
  group_by(person, tweet_id) %>% 
  summarise(rts = sum(in_reply_to_status_id)) %>%  # garbage
  group_by(person) %>% 
  summarise(total_rts = n())

totals
```
```{r, message=FALSE}
# This is broken as the new dataset is missing some columns. I fixed it so that
# it would run but it's output is garbage.
word_by_rts <- tidy_tweets %>% 
  group_by(tweet_id, word, person) %>% 
  summarise(rts = first(in_reply_to_status_id)) %>%  # garbage
  group_by(person, word) %>% 
  summarise(retweets = median(rts), uses = n()) %>% 
  left_join(totals) %>% 
  dplyr::filter(retweets != 0) %>% 
  ungroup()

word_by_rts %>% 
  dplyr::filter(uses >= 5) %>% 
  arrange(desc(retweets))
```

```{r}
word_by_rts %>% 
  dplyr::filter(uses >= 5) %>% 
  group_by(person) %>% 
  top_n(10, retweets) %>% 
  arrange(retweets) %>% 
  ungroup() %>% 
  mutate(word = factor(word, unique(word))) %>% 
  ungroup() %>% 
  ggplot(aes(word, retweets, fill = person)) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~ person, scales = 'free', ncol = 2) +
    coord_flip() +
    labs(x = NULL,
         y = "Median # of retweets for tweets containing each word")
```

```{r, message=FALSE}
# This is broken as the new dataset is missing some columns. I fixed it so that
# it would run but it's output is garbage.
totals <- tidy_tweets %>% 
  group_by(person, tweet_id) %>% 
  summarise(favs = n()) %>%  # garbage line
  group_by(person) %>% 
  summarise(total_favs = sum(favs))

word_by_favs <- tidy_tweets %>% 
  group_by(tweet_id, word, person) %>% 
  summarise(favs = first(in_reply_to_status_id)) %>%  #garbage line
  group_by(person, word) %>% 
  summarise(favorites = median(favs), uses = n()) %>% 
  left_join(totals) %>% 
  dplyr::filter(favorites != 0) %>% 
  ungroup()
```

```{r}
word_by_favs %>% 
  dplyr::filter(uses >= 5) %>% 
  group_by(person) %>% 
  top_n(10, favorites) %>% 
  arrange(favorites) %>% 
  ungroup() %>% 
  mutate(word = factor(word, unique(word))) %>% 
  ungroup() %>% 
  ggplot(aes(word, favorites, fill = person)) + 
    geom_col(show.legend = FALSE) +
    facet_wrap(~ person, scales = "free", ncol = 2) +
    coord_flip() +
    labs(x = NULL,
         y = "Median # of favorites for tweets containing each word")
```

